{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from df2gspread import df2gspread as d2g\n",
    "import inspect as inspect \n",
    "import docx\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from utils import *\n",
    "from spidercharts import *\n",
    "from constants import *\n",
    "from company_profiles import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from Google Spreadsheet using the parameters\n",
    "\n",
    "copy_df = access_google_spreadsheet(\n",
    "    scope = \"https://spreadsheets.google.com/feeds\", \n",
    "    json_keyfile_name = \"Jupyter_meets_GSheet-a279ad757691.json\", # This file has to be in the same folder. \n",
    "    spreadsheet_key = # You get this from the link of the GSheet - hidden before committing to github\n",
    "    worksheet = \"Full_DB\") # Tab you want to import \n",
    "    \n",
    "# Store the df ascsv in case people want to use it in Microsoft (Eww). \n",
    "raw_df = copy_df\n",
    "raw_df = raw_df.set_index(\"Company_Name\")\n",
    "\n",
    "# Get list of columns to keep.  \n",
    "cols_ls = columns_to_keep(\"Score\") # I want to get all scores \n",
    "cols_ls.extend((\"Company_Name\", \"Company_Sector\")) # And add the name of the company and the sector they belong to\n",
    "\n",
    "# Create the scores DataFrame, index is name of company\n",
    "scores_df = copy_df[cols_ls].set_index(\"Company_Name\")\n",
    "# scores_df # It works! Hurray!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns I will need when creating the sections_scores df\n",
    "col_ls = [\"Section_1\", \"Section_2\", \"Section_3\", \"Section_4\", \"Section_5\", \"Section_6\", \"Section_7\", \"Section_8\", \"Section_9\", \"Section_10\", \"TRAC_Index\", \"Bands\"]\n",
    "\n",
    "# Create section_scores_df\n",
    "sections_scores_df = create_sections_scores_df(col_ls, index = scores_df.index)\n",
    "# sections_scores_df # It works! Hurray!\n",
    "\n",
    "# Pupulate the sections_scores_df by calculating the average per company per section and the TRAC Index.\n",
    "# 10 is the number of sections I know from the methodology. \n",
    "sections_scores_df = populate_sections_scores_df(scores_df.index, len(sections_ls), scores_df, sections_scores_df)\n",
    "sections_scores_df = assign_bands(sections_scores_df)\n",
    "#sections_scores_df # It works! Hurray!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns on sector by merging initial copy DataFrame with the section scores DataFrame on Company Name. \n",
    "sections_scores_df = pd.merge(sections_scores_df,copy_df[['Company_Name','Company_Sector']],on='Company_Name', how='left')\n",
    "sections_scores_df = sections_scores_df.set_index(\"Company_Name\")\n",
    "\n",
    "#sections_scores_df.to_csv(\"Sections_scores_aggregated_data\")\n",
    "sections_scores_df # It works! Hurray!\n",
    "\n",
    "# Create dataframe to store the results of sections over the sectors\n",
    "grouped_scores_df = pd.DataFrame()\n",
    "\n",
    "for section_i in list(range(1, 11)):  \n",
    "    grouped_scores_df = grouped_scores_df.append(round(sections_scores_df.groupby(\"Company_Sector\")[\"Section_{}\".format(section_i)].mean(), 2))\n",
    "\n",
    "grouped_scores_df_transposed = grouped_scores_df.transpose()\n",
    "# grouped_scores_df_transposed # It works! Hurray!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the folder structture where we will store the results of the analysis \n",
    "create_folders_structure(root, sub_folders_ls, sections_scores_df.index[:-1])\n",
    "\n",
    "# Before storing our df let's replace all NaN with None for better compatibility with SQL (just in case). \n",
    "scores_df = scores_df.where(scores_df.notnull(), None)\n",
    "sections_scores_df = sections_scores_df.where(sections_scores_df.notnull(), None)\n",
    "grouped_scores_df_transposed = grouped_scores_df_transposed.where(grouped_scores_df_transposed.notnull(), None)\n",
    "\n",
    "# Extend all dataframes created to list of dataframes\n",
    "# List where I wil store all the df I will create and will use to extract them as csv and save them in the folder \"deliverables/data\"\n",
    "\n",
    "all_dataframes_dict = {'scores_df' : scores_df,\n",
    "                       'sections_scores_df': sections_scores_df,\n",
    "                       'grouped_scores_df_transposed' : grouped_scores_df_transposed,\n",
    "                       'raw_data': raw_df}\n",
    "\n",
    "# Store the all dataframes as csv in the corresponding folders. sub_folder_ls[0] is \"data\", see params.py\n",
    "for key, value in all_dataframes_dict.items():\n",
    "    store_file(value, key, sub_folders_ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create company profiles and store them in the company folders created by the create folder structure function. \n",
    "create_save_company_profiles(raw_df, sections_scores_df) # It Works! Hurray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_charts_dfs_dict = create_and_store_df_for_spidercharts(sections_scores_df, grouped_scores_df_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriele/anaconda3/lib/python3.6/site-packages/matplotlib/projections/polar.py:67: RuntimeWarning: invalid value encountered in less\n",
      "  mask = r < 0\n"
     ]
    }
   ],
   "source": [
    "# Let's create the folder structture where we will store the results of the analysis \n",
    "# create_folders_structure(root, sub_folders_ls, sections_scores_df.index[:-1])\n",
    "make_and_save_spidercharts(spider_charts_dfs_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
